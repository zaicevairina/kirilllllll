{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import pandas_gbq as gbq\n",
    "import requests\n",
    "import time\n",
    "\n",
    "project_id = 'arctic-task-238719'\n",
    "private_key='arctic-task-238719-e6a1c5fe056b.json'\n",
    "credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "\n",
    "gbq.context.credentials = credentials\n",
    "gbq.context.project = project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузить посты из определенной группе \n",
    "def upload_post_from_vk_group(username,group_id):\n",
    "    token = 'e7a79876e7a79876e7a79876e9e7ce3561ee7a7e7a79876bb0457d3e507797f75821138'\n",
    "    version = 5.92\n",
    "    count = 100\n",
    "    offset = 0\n",
    "    all_posts = []\n",
    "    x = 100\n",
    "    df = pd.DataFrame(columns=['group_id','group_name', 'post_id','post','annotation','keywords'])\n",
    "    response= requests.get('https://api.vk.com/method/groups.getById',\n",
    "                            params={\n",
    "                                'group_id': group_id,\n",
    "                                'access_token': token,\n",
    "                                'v': version,\n",
    "                                \n",
    "                            }\n",
    "                            )\n",
    "\n",
    "    group_name=response.json()['response'][0]['name']\n",
    "    k=100\n",
    "    while (k==100):\n",
    "        start_time = time.time()\n",
    "        if group_id.isnumeric():\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'owner_id': '-'+group_id,\n",
    "                                        'count': count,\n",
    "                                        'offset':offset\n",
    "                                    }\n",
    "                                    )\n",
    "        else:\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'domain': group_id,\n",
    "                                        'count': count,\n",
    "                                        'offset':offset\n",
    "                                    }\n",
    "                                    )\n",
    "        data = response.json()['response']['items']\n",
    "        offset += 100\n",
    "        k=len(data)\n",
    "        j=0\n",
    "        for i in range(k):\n",
    "            annotation = 'annotation'\n",
    "            keywords = 'keywords'\n",
    "            post_id = data[i]['id']\n",
    "            post = data[i]['text']\n",
    "            if post!='':\n",
    "                df.loc[j] = [group_id,group_name,int(post_id), post,annotation,keywords]\n",
    "                j+=1\n",
    "        gbq.to_gbq(df,'dataset.vk_storage_'+username, project_id , if_exists = 'append')\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "# upload_post_from_vk_group('kirill','192959150')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалить из биб для vk группу по id \n",
    "def delete_row_group_from_userlibrary(username,group_id):\n",
    "    credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "\n",
    "    client = bigquery.Client(project='arctic-task-238719',credentials=credentials)\n",
    "    \n",
    "    Query=f'DELETE  FROM dataset.vk_storage_{username} WHERE group_id = \\'{group_id}\\''\n",
    "    query_job = client.query(Query)\n",
    "    \n",
    "\n",
    "delete_row_group_from_userlibrary('kirill','meaning_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалить из личной биб со статьями по названию и автору\n",
    "def delete_row_article_from_userlibrary(username,author,title):\n",
    "    credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "\n",
    "    client = bigquery.Client(project='arctic-task-238719',credentials=credentials)\n",
    "    Query=f'DELETE  FROM dataset.{username} WHERE author like \\'%{author}%\\' and title likw \\'%{title}%\\' '\n",
    "    query_job = client.query(Query)\n",
    "\n",
    "# title='Рассеяние энергии механических колебаний в мягких ферромагнитных материалах в зависимости от фазы колебаний'\n",
    "# delete_row_article_from_userlibrary('kirill','Глотова Людмила Сергеевна',title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "from google.oauth2 import service_account\n",
    "project_id = 'arctic-task-238719'\n",
    "private_key='arctic-task-238719-e6a1c5fe056b.json'\n",
    "import json\n",
    "from google.cloud import bigquery\n",
    "credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "from pandas.io import gbq\n",
    "stops = set(stopwords.words(\"english\")) | set(stopwords.words(\"russian\"))\n",
    "import pandas as pd\n",
    "morph=pymorphy2.MorphAnalyzer()\n",
    "stemmer=SnowballStemmer('russian')\n",
    "def search_in_user_vk_library(username,word='',mode='post'):\n",
    "    \n",
    "    if mode=='post_from_group':\n",
    "        group_name,word=word.split(',')\n",
    "        \n",
    "        word = re.sub(\"[^а-яА-Яa-zA-Z0-9]\", \" \", word)\n",
    "        words = word.lower().split()\n",
    "        words = [w for w in words if not w in stops]\n",
    "        words = [stemmer.stem(w) for w in words]\n",
    "        if words=='':\n",
    "            return \"некорректный ввод\"\n",
    "        \n",
    "        Query = f'SELECT * FROM dataset.vk_storage_{username}  WHERE group_name=\\'{group_name}\\' and (post LIKE \\''\n",
    "        for word in words:\n",
    "            Query+='%{}'.format(word)\n",
    "        Query +='%\\' or post LIKE \\' '\n",
    "        flag=True\n",
    "        for word in words:\n",
    "            if flag==True:\n",
    "                Query+='%{}'.format(word.capitalize())\n",
    "                flag=False\n",
    "            else:\n",
    "                Query+='%{}'.format(word)\n",
    "        Query +='%\\')'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    word = re.sub(\"[^а-яА-Яa-zA-Z0-9]\", \" \", word)\n",
    "    words = word.lower().split()\n",
    "    words = [w for w in words if not w in stops]\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    if words=='':\n",
    "        return \"некорректный ввод\"\n",
    "\n",
    "    if mode=='post':\n",
    "        Query = f'SELECT * FROM dataset.vk_storage_{username}  WHERE post LIKE \\''\n",
    "        for word in words:\n",
    "            Query+='%{}'.format(word)\n",
    "        Query +='%\\' or post LIKE \\' '\n",
    "        flag=True\n",
    "        for word in words:\n",
    "            if flag==True:\n",
    "                Query+='%{}'.format(word.capitalize())\n",
    "                flag=False\n",
    "            else:\n",
    "                Query+='%{}'.format(word)\n",
    "        Query +='%\\''\n",
    "          \n",
    "    df = gbq.read_gbq(Query, project_id, credentials=credentials)\n",
    "    \n",
    "    result = df.values.tolist()\n",
    "    return result\n",
    "\n",
    "# search(mode='kws',word='физика')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The default value for dialect is changing to \"standard\" in a future version. Pass in dialect=\"legacy\" or set pandas_gbq.context.dialect=\"legacy\" to disable this warning.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['hghg', '192959150'], ['Data Science', 'datascience']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def show_all_groups(username):\n",
    "    \n",
    "    Query = f'SELECT  group_name,group_id FROM dataset.vk_storage_{username}  group by group_name,group_id'\n",
    "    df = gbq.read_gbq(Query, project_id, credentials=credentials)\n",
    "    result = df.values.tolist()\n",
    "    \n",
    "    return  result\n",
    "\n",
    "# search(mode='kws',word='физика')\n",
    "\n",
    "show_all_groups('kirill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_user_library(username):\n",
    "    \n",
    "    Query = f'SELECT authors,title FROM dataset.{username}'\n",
    "    df = gbq.read_gbq(Query, project_id, credentials=credentials)\n",
    "    result = df.values.tolist()\n",
    "    \n",
    "    return  result\n",
    "\n",
    "# search(mode='kws',word='физика')\n",
    "\n",
    "# show_user_library(username='kirill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1/1 [00:01<00:00,  1.42s/rows]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def data_about_group_for_update(username,group_id,credentials=credentials):\n",
    "    \n",
    "    Query = f'SELECT group_id,MAX(post_id) as last FROM dataset.vk_storage_{username} where group_id=\\'{group_id}\\' group by group_id'\n",
    "    df = gbq.read_gbq(Query, project_id, credentials=credentials)\n",
    "    result = df['last'].values.tolist()\n",
    "    \n",
    "    return  result\n",
    "\n",
    "# search(mode='kws',word='физика')\n",
    "\n",
    "data_about_group_for_update(username='kirill',group_id='192959150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_post_from_vk_group(username,group_id,credentials):\n",
    "    last_post_id = data_about_group_for_update(username,group_id,credentials)[0]\n",
    "    \n",
    "    token = 'e7a79876e7a79876e7a79876e9e7ce3561ee7a7e7a79876bb0457d3e507797f75821138'\n",
    "    version = 5.92\n",
    "    count = 100\n",
    "    offset = 0\n",
    "    all_posts = []\n",
    "    x = 100\n",
    "    df = pd.DataFrame(columns=['group_id','group_name', 'post_id','post','annotation','keywords'])\n",
    "    response= requests.get('https://api.vk.com/method/groups.getById',\n",
    "                            params={\n",
    "                                'group_id': group_id,\n",
    "                                'access_token': token,\n",
    "                                'v': version,\n",
    "                                \n",
    "                            }\n",
    "                            )\n",
    "\n",
    "    group_name=response.json()['response'][0]['name']\n",
    "    k=100\n",
    "    while (k==100):\n",
    "        start_time = time.time()\n",
    "        if group_id.isnumeric():\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'owner_id': '-'+group_id,\n",
    "                                        'count': count,\n",
    "                                        'offset':offset\n",
    "                                    }\n",
    "                                    )\n",
    "        else:\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'domain': group_id,\n",
    "                                        'count': count,\n",
    "                                        'offset':offset\n",
    "                                    }\n",
    "                                    )\n",
    "        data = response.json()['response']['items']\n",
    "        \n",
    "        k=len(data)\n",
    "        offset += 100\n",
    "        j=0\n",
    "        for i in range(len(data)):\n",
    "            annotation = 'annotation'\n",
    "            keywords = 'keywords'\n",
    "            post_id = data[i]['id']\n",
    "            post = data[i]['text']\n",
    "            if post!='' and int(post_id)!=last_post_id:\n",
    "                df.loc[j] = [group_id,group_name,int(post_id), post,annotation,keywords]\n",
    "                j+=1\n",
    "            elif int(post_id)==last_post_id:\n",
    "                break\n",
    "            \n",
    "        \n",
    "        if len(df)!=0:\n",
    "            gbq.to_gbq(df,'dataset.vk_storage_'+username, project_id , if_exists = 'append')\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# update_post_from_vk_group('kirill','192959150',credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import pandas_gbq as gbq\n",
    "\n",
    "project_id = 'arctic-task-238719'\n",
    "private_key='arctic-task-238719-e6a1c5fe056b.json'\n",
    "credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "\n",
    "gbq.context.credentials = credentials\n",
    "gbq.context.project = project_id\n",
    "\n",
    "\n",
    "def upload_user_bd(list_of_lists,username):\n",
    "    try:\n",
    "        df = pd.DataFrame(list_of_lists, columns=['author','title','keywords'])\n",
    "        gbq.to_gbq(df,'dataset.'+username, project_id , if_exists = 'append'   )\n",
    "    return True\n",
    "    \n",
    "    except:\n",
    "        return -1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
